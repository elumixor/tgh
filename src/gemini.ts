import { GoogleGenAI, type PersonGeneration } from "@google/genai";
import { env } from "./env";

export interface GenerateImageParams {
  prompt: string;
  aspectRatio?: "1:1" | "3:4" | "4:3" | "9:16" | "16:9";
  numberOfImages?: 1 | 2 | 3 | 4;
  personGeneration?: PersonGeneration;
}

export interface EditImageParams {
  prompt: string;
  referenceImages: string[];
  aspectRatio?: "1:1" | "3:4" | "4:3" | "9:16" | "16:9";
}

interface GeminiImagePart {
  inlineData: {
    mimeType: string;
    data: string;
  };
}

export class GeminiClient {
  private readonly client = new GoogleGenAI({ apiKey: env.GEMINI_API_KEY });
  private readonly model = "gemini-2.5-flash-image";
  private readonly visionModel = "gemini-2.0-flash";

  async generateImage(params: GenerateImageParams): Promise<string[]> {
    const numberOfImages = params.numberOfImages || 1;
    const images: string[] = [];

    for (let i = 0; i < numberOfImages; i++) {
      const config: Record<string, unknown> = {
        responseModalities: ["IMAGE"],
      };

      if (params.aspectRatio) config.imageConfig = { aspectRatio: params.aspectRatio };
      if (params.personGeneration) config.personGeneration = params.personGeneration;

      const response = await this.client.models.generateContent({
        model: this.model,
        contents: [{ text: params.prompt }],
        config,
      });

      if (response.candidates?.[0]?.content?.parts) {
        for (const part of response.candidates[0].content.parts) {
          if (part.inlineData?.data) images.push(part.inlineData.data);
        }
      }
    }

    if (images.length === 0) throw new Error("No images generated by Gemini API");

    return images;
  }

  async editImage(params: EditImageParams): Promise<string> {
    const imageParts: (GeminiImagePart | { text: string })[] = [];

    for (const imageUrl of params.referenceImages) {
      const imagePart = await this.urlToImagePart(imageUrl);
      imageParts.push(imagePart);
    }

    imageParts.push({ text: params.prompt });

    const response = await this.client.models.generateContent({
      model: this.model,
      contents: imageParts,
      config: {
        responseModalities: ["image"],
        ...(params.aspectRatio && {
          outputImageAspectRatio: params.aspectRatio,
        }),
      },
    });

    if (response.candidates?.[0]?.content?.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData?.data) return part.inlineData.data;
      }
    }

    throw new Error("No image generated by Gemini API");
  }

  private async urlToImagePart(url: string): Promise<GeminiImagePart> {
    const response = await fetch(url);
    if (!response.ok) throw new Error(`Failed to fetch image from URL: ${response.status}`);

    const arrayBuffer = await response.arrayBuffer();
    const base64 = Buffer.from(arrayBuffer).toString("base64");

    let mimeType = response.headers.get("content-type") || "image/jpeg";

    if (mimeType === "application/octet-stream" || !mimeType.startsWith("image/")) {
      if (url.includes(".png")) mimeType = "image/png";
      else if (url.includes(".webp")) mimeType = "image/webp";
      else mimeType = "image/jpeg";
    }

    return { inlineData: { mimeType, data: base64 } };
  }

  async analyzeImage(imageUrl: string, prompt?: string): Promise<string> {
    const imagePart = await this.urlToImagePart(imageUrl);
    const textPrompt = prompt || "Analyze this image in detail. Describe what you see.";

    const response = await this.client.models.generateContent({
      model: this.visionModel,
      contents: [imagePart, { text: textPrompt }],
    });

    const text = response.candidates?.[0]?.content?.parts?.find((part) => "text" in part);
    if (!text || !("text" in text) || !text.text) throw new Error("No text response from Gemini vision API");

    return text.text;
  }

  convertBase64ToBuffer(base64: string): Buffer {
    return Buffer.from(base64, "base64");
  }
}

export const geminiClient = new GeminiClient();
